{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and basic cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports and a custom function to load the dataset along with the column specifying the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>section</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nMientras sucedía lo referido con los Carer...</td>\n",
       "      <td>1</td>\n",
       "      <td>PAN11</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Las escribí á V. E., y V. E. las trasladó al ...</td>\n",
       "      <td>1</td>\n",
       "      <td>PAN11</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I pass over in silence, not to annoy the read...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAN11</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cambiaban las formas, pero el alma permanecía...</td>\n",
       "      <td>1</td>\n",
       "      <td>PAN11</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rose from the bench that worked,\\nand walked ...</td>\n",
       "      <td>0</td>\n",
       "      <td>PAN11</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label section label_name\n",
       "0  \\n\\nMientras sucedía lo referido con los Carer...     1   PAN11         es\n",
       "1   Las escribí á V. E., y V. E. las trasladó al ...     1   PAN11         es\n",
       "2   I pass over in silence, not to annoy the read...     0   PAN11         en\n",
       "3   Cambiaban las formas, pero el alma permanecía...     1   PAN11         es\n",
       "4   Rose from the bench that worked,\\nand walked ...     0   PAN11         en"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def get_dataset(foldername,rootpath):\n",
    "    path = os.path.join(rootpath,foldername)\n",
    "    data = load_files(path,encoding=\"utf-8\")  \n",
    "    Xa, ya, y_names = data.data, data.target, data.target_names\n",
    "    df = pd.DataFrame(list(zip(Xa,ya)),columns = [\"text\",\"label\"])\n",
    "    df[\"section\"] = foldername\n",
    "    df[\"label_name\"] = df[\"label\"].apply(lambda x: y_names[int(x)] )\n",
    "    return df\n",
    "\n",
    "df = pd.DataFrame(columns=[\"text\",\"label\",\"section\",\"label_name\"])\n",
    "\n",
    "for name in os.listdir(\"documents_challenge\"):\n",
    "    df = df.append(get_dataset(name,\"./documents_challenge\"))\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the loading process is correct and all documents are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23128, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic text cleaning. After the process is complete, the cleaned data is stored on a csv file in in order not to have to repeat the cleaning process every time further analysis is to be conducted. Steps included in this function are the most basic ones. Further exploration should explore frequencies, n_grams and substituting named entities by a chosen label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n",
      "Done! Writing file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import unidecode\n",
    "import re\n",
    "def doClean(text,language):   \n",
    "\n",
    "\n",
    "    # Remove all that doesn't resemble a word\n",
    "    a = re.sub(r'\\W', ' ', text)\n",
    "    # Remove numbers\n",
    "    a = re.sub(\" \\d+\", \"label_num\", a)\n",
    "    # Remove extra spaces\n",
    "    a = re.sub(r'\\s+', ' ', a, flags=re.I)\n",
    "    # Transform to lowercase\n",
    "    a = a.lower()\n",
    "    # remove stopwords by language\n",
    "    if language == \"en\":\n",
    "        a = a.split()\n",
    "        a = [ word for word in a if word not in stopwords.words(\"english\")]\n",
    "        a = \" \".join(a)\n",
    "    elif language == \"es\":\n",
    "        a = a.split()\n",
    "        a = [ word for word in a if word not in stopwords.words(\"spanish\")]\n",
    "        a = \" \".join(a)\n",
    "    elif language == \"fr\":\n",
    "        a = a.split()\n",
    "        a = [ word for word in a if word not in stopwords.words(\"french\")]\n",
    "        a = \" \".join(a)\n",
    "    return a\n",
    "print(\"Cleaning text...\")\n",
    "df[\"text\"] = df.apply(lambda x : doClean(x[\"text\"],x[\"label_name\"]),axis=1)\n",
    "print(\"Done! Writing file...\")\n",
    "df.to_csv(\"clandata.csv\",index=False)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
